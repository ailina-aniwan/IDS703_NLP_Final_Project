{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to /Users/liuliangcheng/Desktop/Duke/IDS_NLP/final/cleaned_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/Users/liuliangcheng/Desktop/Duke/IDS_NLP/final/Womens Clothing E-Commerce Reviews.csv.zip\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Remove rows with missing Review Text\n",
    "cleaned_data = data.dropna(subset=[\"Review Text\"]).reset_index(drop=True)\n",
    "\n",
    "# Step 2: Map Ratings to Sentiment Categories\n",
    "# (1-2: Dissatisfied, 3: Neutral, 4-5: Satisfied)\n",
    "cleaned_data[\"Sentiment\"] = cleaned_data[\"Rating\"].map(\n",
    "    {1: \"Dissatisfied\", 2: \"Dissatisfied\", 3: \"Neutral\", 4: \"Satisfied\", 5: \"Satisfied\"}\n",
    ")\n",
    "\n",
    "# Step 3: Text Preprocessing (optional for BERT)\n",
    "# Remove special characters and strip extra spaces\n",
    "cleaned_data[\"Review Text\"] = (\n",
    "    cleaned_data[\"Review Text\"]\n",
    "    .str.replace(r\"[^a-zA-Z0-9\\s]\", \"\", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Step 4: Save the cleaned data\n",
    "output_path = \"/Users/liuliangcheng/Desktop/Duke/IDS_NLP/final/cleaned_reviews.csv\"\n",
    "cleaned_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaned dataset appears to be in excellent condition for further modeling:\n",
    "\n",
    "Missing Values:\n",
    "\n",
    "No missing values in the Review Text column.\n",
    "No missing values in the Sentiment column.\n",
    "Total Entries:\n",
    "\n",
    "The dataset contains 22,641 entries, which is sufficient for fine-tuning a BERT model.\n",
    "Sentiment Distribution:\n",
    "\n",
    "Satisfied: 17,448 entries\n",
    "Neutral: 2,823 entries\n",
    "Dissatisfied: 2,370 entries\n",
    "While there is some imbalance favoring the \"Satisfied\" category, this can be managed during model training with techniques like class weighting or oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option1 Oversampling\n",
    "Random Oversampling: Duplicate existing samples from minority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "Satisfied       17448\n",
      "Neutral         17448\n",
      "Dissatisfied    17448\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    " from sklearn.utils import resample\n",
    "\n",
    "# Separate each class\n",
    "satisfied = cleaned_data[cleaned_data['Sentiment'] == 'Satisfied']\n",
    "neutral = cleaned_data[cleaned_data['Sentiment'] == 'Neutral']\n",
    "dissatisfied = cleaned_data[cleaned_data['Sentiment'] == 'Dissatisfied']\n",
    "\n",
    "# Oversample the minority classes\n",
    "neutral_oversampled = resample(neutral, replace=True, n_samples=len(satisfied), random_state=42)\n",
    "dissatisfied_oversampled = resample(dissatisfied, replace=True, n_samples=len(satisfied), random_state=42)\n",
    "\n",
    "# Combine all classes\n",
    "balanced_data = pd.concat([satisfied, neutral_oversampled, dissatisfied_oversampled])\n",
    "\n",
    "print(balanced_data['Sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# option2 Weighted Loss Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([0.4325, 2.6734, 3.1844])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "# Ensure 'classes' is a NumPy array\n",
    "classes = np.array([\"Satisfied\", \"Neutral\", \"Dissatisfied\"])\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(\n",
    "    \"balanced\", classes=classes, y=cleaned_data[\"Sentiment\"]\n",
    ")\n",
    "\n",
    "# Convert class weights to a PyTorch tensor\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Output the class weights for confirmation\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class weights tensor([0.4325, 2.6734, 3.1844]) indicate that your dataset has significant class imbalance:\n",
    "\n",
    "Satisfied (weight: 0.4325): Majority class with the least weight.\n",
    "Neutral (weight: 2.6734): Minority class with higher weight.\n",
    "Dissatisfied (weight: 3.1844): Smallest class, given the highest weight to balance its contribution.\n",
    "What This Means:\n",
    "The model will \"penalize\" errors on the minority classes (Neutral and Dissatisfied) more than errors on the majority class (Satisfied). This encourages the model to pay more attention to underrepresented classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
